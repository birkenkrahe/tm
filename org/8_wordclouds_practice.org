#+TITLE: Text mining in practice - Bag of Words - Intro to word clouds
#+AUTHOR: [name...] (...)
#+SUBTITLE: Digital Humanities DSC 105 Spring 2023
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README

- This lecture closely follows the DataCamp lesson "Text Mining with
  Bag-of-Words in R" by Ted Kwartler, chapter 2, lesson 2, "Intro to
  word clouds" ([[https://campus.datacamp.com/courses/text-mining-with-bag-of-words-in-r/][Link]]).

- Download and open the practice file ~8_wordclouds_practice.org~ from
  GitHub to code along.

- In this lecture & practice:
  1) simple word cloud creation using Chardonnay tweets
  2) adding stop words to change word cloud
  3) improve word cloud appearance and insights

* Get the corpus data and the R packages

- Download ~corpora.R~ from GitHub ([[https://bit.ly/tm-corpora][bit.ly/tm-corpora]])

- Run the file on the shell (~M-x eshell~) as a batch job:
  #+begin_src sh
    R CMD BATCH corpora.R
    ls -al .RData
  #+end_src

- Load the ~.RData~ file in your current R session and check that
  packages and user-defined objects were loaded:
  #+begin_src R
    load("~/Downloads/.RData")
    search()
    ls()
  #+end_src

- You need the ~clean_coffee~ and ~clean_chardonnay~ corpora.

- If we don't finish with a session, save your data from now on:
  #+begin_src R
    save.image(file=".RData")
    shell("ls -al .RData")
  #+end_src

* Intro to word clouds

- Look at the corpus:
  #+begin_src R
    clean_chardonnay
  #+end_src

  #+RESULTS:
  : <<VCorpus>>
  : Metadata:  corpus specific: 0, document level (indexed): 0
  : Content:  documents: 1000

* Convert TDM to matrix

- Convert Chardonnay TDM to a matrix and check its dimensions:
  #+name: chardonnay_m
  #+begin_src R
    library(tm)
    chardonnay_tdm <- TermDocumentMatrix(clean_chardonnay)
    chardonnay_m <- as.matrix(chardonnay_tdm)
    dim(chardonnay_m)
  #+end_src

  #+RESULTS: chardonnay_m
  : [1] 3067 1000

* Create the frequency table

- The starting point of any visualization is a frequency table - it
  only has two columns: terms (~term~) and their counts (~num~).

- Sum rows and sort by frequency:
  #+name: word_freq
  #+begin_src R
    term_frequency <- rowSums(chardonnay_m)
    term_frequency <- sort(term_frequency, decreasing=TRUE)
    word_freq <- data.frame(term = names(term_frequency),
                            num = term_frequency)
    rownames(word_freq) <- NULL
    head(word_freq,n=10)
  #+end_src

  #+RESULTS: word_freq
  #+begin_example
           term num
  1  chardonnay 822
  2         amp 120
  3      marvin 104
  4        wine  83
  5        gaye  76
  6        just  75
  7       glass  63
  8        like  55
  9      bottle  47
  10        lol  43
  #+end_example

* NEXT Add stop words and re-run the cleaning code

- The words ~amp~, ~wine~ and ~glass~ do not help much - how can we get rid
  of them at this stage of our investigation? Do you know what "amp"
  means in this context?[fn:1]
  #+begin_quote
  Answer:
  1) download the latest version of ~corpora.R~ from GitHub.
  2) add these words to the stopwords cleaning function in ~corpora.R~
  3) run the batch job with ~R CMD BATCH~
  4) re-load ~.RData~ in this file.
  You'll see that the number of words (records) has gone down and the
  list of top frequency words is changed.
  #+end_quote

- After cleaning out the additional words, reload the data, create the
  TDM and the word frequency data frame:
  #+begin_src R
    load("~/Downloads/.RData")
    <<chardonnay_m>>
    <<word_freq>>
  #+end_src

* Using the ~wordcloud~ function

- We want to create word clouds. Is there a ~wordcloud~ function in ~tm~
  or ~qdap~ or ~base~? How can you find out? Load these packages (again,
  just in case) and check each of them for the function:
  #+begin_src R
 
  #+end_src

- To create a wordcloud, use the ~wordcloud~ function. Look at the ~help~!
  (Go to the R console buffer ~*R*~ and type ~?wordcloud~.)

- Use the column vectors ~term~ and ~num~ for the ~words~ and ~freq~
  parameters, respectively:
  #+begin_src R :results graphics file :file wordcloud1.png
    library(wordcloud)
    wordcloud(words=
              freq=
              max.words=
              color= )
  #+end_src

- Print out frirst 10 entries of ~term_frequency~:
  #+begin_src R

  #+end_src

- Extract the terms 2 to 11 using ~names~ on ~term_frequency~ and save
  them to an object ~terms_vec~. Look at its values 2 through 11:
  #+begin_src R

  #+end_src

- Create a wordcloud using ~term_vec~ as the words, and ~term_frequency~
  (defined earlier before creating the data frame ~word_freq~) as the
  values. Add ~max.words=50~ and ~colors="red"~:
  #+begin_src R :results graphics file :file termcloud.png
    wordcloud(words=
              freq=
              max.words=
              colors= )
  #+end_src

- Review a cleaned tweet: do you remember how to index corpus tweets?
  Print ~clean_chardonnay~ tweet no. 24:
  #+begin_src R

  #+end_src
  
- Define a vector ~stops~ with the stop words from ~stopwords("en")~ and
  the words 'just' and 'like':
  #+begin_src R
    stops <- c(stopwords("en"), 'just','like')
  #+end_src

- Create a corpus ~cc~ by applying ~tm_map~ to ~clean_chardonnay~ with the
  function ~removeWords~ and the additional argument ~stops~.
  #+begin_src R

  #+end_src

- Now print tweet 24 from the corpus ~ccc~:
  #+begin_src R

  #+end_src
  
- To see the updated word cloud, re-run the code chunks from before
  with the new, cleaner corpus, then go back and rerun the last plot:
  #+begin_src R
    clean_chardonnay <- ccc
    <<chardonnay_m>>
    <<word_freq>>
  #+end_src

* Improve word clouds with different colors

- The available colors are stored in a ~character~ vector ~colors()~. Look
  at the ~head~ of this vector:
  #+begin_src R

  #+end_src

- Verify that there are 657 available colors:
  #+begin_src R

  #+end_src

- Look at the arguments of ~wordcloud~:
  #+begin_src R
    <<load_packages>>

  #+end_src

- Check the structure of ~word_freq~ which you defined above:
  #+begin_src R

  #+end_src

- Create a ~wordcloud~ for ~word_freq~:    
  1) as ~words~, use the ~term~ column
  2) as ~freq~, use the ~num~ column
  3) limit ~max.words~ to 100
  4) for ~colors~, select ~grey80~, ~darkgoldenrod1~ and ~tomato~ 
  #+begin_src R :results graphics file :file wordcloud_color.png
    <<word_freq>>

  #+end_src

* Using prebuilt color palettes: ~viridisLite~

- Install ~viridisLite~ in the R console, load it and ~search~ for it:
  #+begin_src R

  #+end_src

- Using ~ls~, look at the contents of the ~viridisLite~ package:
  #+begin_src R

  #+end_src

- Check the arguments of ~viridisLite::cividis~:
  #+begin_src R

  #+end_src

- Select 5 colors from the ~turbo~ color map and store them in a vector
  ~color_pal~:
  #+begin_src R :results silent

  #+end_src

- Print the hex-codes for ~color_pal~ to the console:
  #+begin_src R 

  #+end_src  

- Create a word cloud from the Chardonnay tweets ~word_freq~, include
  100 terms, and set the ~colors~ to the ~color_pal~ palette:
  #+begin_src R :results graphics file :file colorcloud.png

  #+end_src

* Load packages
#+name: load_packages
#+begin_src R
load_packages <- function() {
    library(tm)
    library(qdap)
    library(SnowballC)
    library(wordcloud)
    search()
}
load_packages()
#+end_src
