#+TITLE: Text mining in practice - Bag of Words - Intro to word clouds
#+AUTHOR: Marcus Birkenkrahe
#+SUBTITLE: Digital Humanities DSC 105 Spring 2023
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README

- This lecture closely follows the DataCamp lesson "Text Mining with
  Bag-of-Words in R" by Ted Kwartler, chapter 2, lesson 2, "Intro to
  word clouds" ([[https://campus.datacamp.com/courses/text-mining-with-bag-of-words-in-r/][Link]]).

- Download and open the practice file ~8_wordclouds_practice.org~ from
  GitHub to code along.

- In this lecture & practice:
  1) simple word cloud creation using Chardonnay tweets
  2) adding stop words to change word cloud
  3) improve word cloud appearance and insights

* Get the corpus data and the R packages

- Download ~corpora.R~ from GitHub ([[https://bit.ly/tm-corpora][bit.ly/tm-corpora]])

- Run the file on the shell (~M-x eshell~) as a batch job:
  #+begin_src sh
    R CMD BATCH corpora.R
    ls -al .RData
  #+end_src

- Load the ~.RData~ file in your current R session and check that
  packages and user-defined objects were loaded:
  #+begin_src R
    <<load_packages>>
    load("c:/Users/birkenkrahe/Downloads/.RData")
    search()
    ls()
  #+end_src

  #+RESULTS:
  #+begin_example
   [1] ".GlobalEnv"               "package:wordcloud"       
   [3] "package:SnowballC"        "package:qdap"            
   [5] "package:RColorBrewer"     "package:qdapTools"       
   [7] "package:qdapRegex"        "package:qdapDictionaries"
   [9] "package:tm"               "package:NLP"             
  [11] "ESSR"                     "package:stats"           
  [13] "package:graphics"         "package:grDevices"       
  [15] "package:utils"            "package:datasets"        
  [17] "package:stringr"          "package:httr"            
  [19] "package:methods"          "Autoloads"               
  [21] "package:base"
   [1] ".GlobalEnv"               "package:wordcloud"       
   [3] "package:SnowballC"        "package:qdap"            
   [5] "package:RColorBrewer"     "package:qdapTools"       
   [7] "package:qdapRegex"        "package:qdapDictionaries"
   [9] "package:tm"               "package:NLP"             
  [11] "ESSR"                     "package:stats"           
  [13] "package:graphics"         "package:grDevices"       
  [15] "package:utils"            "package:datasets"        
  [17] "package:stringr"          "package:httr"            
  [19] "package:methods"          "Autoloads"               
  [21] "package:base"
   [1] "api_key"                 "ask_chatgpt"            
   [3] "chardonnay_corpus"       "chardonnay_df"          
   [5] "chardonnay_m"            "chardonnay_src"         
   [7] "chardonnay_tdm"          "chardonnay_vec"         
   [9] "clean_chardonnay"        "clean_chardonnay_corpus"
  [11] "clean_coffee"            "clean_coffee_corpus"    
  [13] "coffee_corpus"           "coffee_df"              
  [15] "coffee_src"              "coffee_vec"             
  [17] "load_packages"           "M"                      
  [19] "term_frequency"          "word_freq"
  #+end_example

- You need the ~clean_coffee~ and ~clean_chardonnay~ corpora.

- If we don't finish with a session, save your data from now on:
  #+begin_src R
    save.image(file=".RData")
    shell("ls -al .RData")
  #+end_src

  #+RESULTS:
  : -rwx------+ 1 birkenkrahe Domain Users 659656 Mar 28 15:53 .RData

* IN PROGRESS Intro to word clouds

- Our starting point is the cleaned corpus of "Chardonnay" tweets,
  ~clean_chardonnay~.

- Look at the corpus:
  #+begin_src R
    clean_chardonnay
  #+end_src

  #+RESULTS:
  : <<VCorpus>>
  : Metadata:  corpus specific: 0, document level (indexed): 0
  : Content:  documents: 1000

* Convert TDM to matrix

- Convert Chardonnay TDM to a matrix and check its dimensions:
  #+name: chardonnay_m
  #+begin_src R
    library(tm)
    chardonnay_tdm <- TermDocumentMatrix(clean_chardonnay)
    chardonnay_m <- as.matrix(chardonnay_tdm)
    dim(chardonnay_m)
  #+end_src

  #+RESULTS: chardonnay_m
  : [1] 3067 1000

* Create the frequency table

- The starting point of any visualization is a frequency table - it
  only has two columns: terms (~term~) and their counts (~num~).

- Sum rows and sort by frequency:
  #+name: word_freq
  #+begin_src R
    term_frequency <- rowSums(chardonnay_m)
    term_frequency <- sort(term_frequency, decreasing=TRUE)
    word_freq <- data.frame(term = names(term_frequency),
                            num = term_frequency)
    rownames(word_freq) <- NULL
    head(word_freq,n=10)
  #+end_src

  #+RESULTS: word_freq
  #+begin_example
           term num
  1  chardonnay 822
  2         amp 120
  3      marvin 104
  4        wine  83
  5        gaye  76
  6        just  75
  7       glass  63
  8        like  55
  9      bottle  47
  10        lol  43
  #+end_example

* Add stop words and re-run the cleaning code

- The words ~amp~, ~wine~ and ~glass~ do not help much - how can we get rid
  of them at this stage of our investigation? Do you know what "amp"
  means in this context?[fn:1]
  #+begin_quote
  Answer:
  1) download the latest version of ~corpora.R~ from GitHub.
  2) add these words to the stopwords cleaning function in ~corpora.R~
  3) run the batch job with ~R CMD BATCH~
  4) re-load ~.RData~ in this file.
  You'll see that the number of words (records) has gone down and the
  list of top frequency words is changed.
  #+end_quote

- After cleaning out the additional words, reload the data, create the
  TDM and the word frequency data frame:
  #+begin_src R
    load("~/Downloads/.RData")
    <<chardonnay_m>>
    <<word_freq>>
  #+end_src

  #+RESULTS:
  #+begin_example
  [1] 3067 1000
           term num
  1  chardonnay 822
  2         amp 120
  3      marvin 104
  4        wine  83
  5        gaye  76
  6        just  75
  7       glass  63
  8        like  55
  9      bottle  47
  10        lol  43
  #+end_example

* Using the ~wordcloud~ function

- We want to create word clouds. Is there a ~wordcloud~ function in ~tm~
  or ~qdap~ or ~base~? How can you find out? Load these packages (again,
  just in case) and check each of them for the function:
  #+begin_src R
    library(tm)
    library(qdap)
    library(wordcloud)
    any(ls('package:tm')=="wordcloud")
    any(ls('package:qdap')=="wordcloud")
    any(ls('package:wordcloud')=="wordcloud")
  #+end_src

- To create a wordcloud, use the ~wordcloud~ function. Look at the ~help~.

- Use the column vectors ~term~ and ~num~ for the ~words~ and ~freq~
  parameters, respectively:
  #+begin_src R :results graphics file :file ../img/wordcloud1.png
    library(wordcloud)
    wordcloud(words=word_freq$term,
              freq=word_freq$num,
              max.words=100,
              color="blue")
  #+end_src

- Print out frirst 10 entries of ~term_frequency~:
  #+begin_src R
    term_frequency[1:10]
  #+end_src

- Extract the terms 2 to 11 using ~names~ on ~term_frequency~ and call the
  vector of strings ~terms_vec~. Show the entries 2 to 11:
  #+begin_src R
    terms_vec <- names(term_frequency)
    terms_vec[2:11]
    length(terms_vec)
    head(table(term_frequency))
  #+end_src

- Create a wordcloud using ~term_vec~ as the words, and ~term_frequency~
  (defined earlier before creating the data frame ~word_freq~) as the
  values. Add ~max.words=50~ and ~colors="red"~:
  #+begin_src R :results graphics file :file ../img/termcloud.png
    wordcloud(words=terms_vec,
              freq=term_frequency,
              max.words=50,
              colors="red")
  #+end_src

- Review a cleaned tweet: do you remember how to index corpus tweets? 
  #+begin_src R
    content(clean_chardonnay[[24]])
  #+end_src
  
- You can add to the stopwords, and run ~tm_map~ with ~removeWords~ on the
  clean corpus to remove additional words:
  #+begin_src R
    content(clean_chardonnay[[24]])
    stops <- c(stopwords("en"), 'just','like')
    tail(stops)
    clean_chardonnay_corpus <- tm_map(clean_chardonnay,
                                      removeWords,
                                      stops)
    content(clean_chardonnay_corpus[[24]])    
  #+end_src

  #+RESULTS:
  : [1] " brought marvin gaye chardonnay"
  : [1] "too"        "very"       "just"       "like"       "chardonnay"
  : [6] "amp"
  : [1] " brought marvin gaye "

- To see the updated word cloud, re-run the code chunks from before
  with the new, cleaner corpus, then go back and rerun the last plot:
  #+begin_src R
    clean_chardonnay <- clean_chardonnay_corpus
    <<chardonnay_m>>
    <<word_freq>>
  #+end_src

  #+RESULTS:
  #+begin_example
  [1] 3063 1000
       term num
  1  marvin 104
  2    wine  83
  3    gaye  76
  4   glass  63
  5  bottle  47
  6     lol  43
  7  little  35
  8    rose  34
  9    dont  32
  10    get  32
  #+end_example

* TODO Improve word clouds with different colors

- The available colors are stored in a ~character~ vector ~colors()~. Look
  at the ~head~ of the vector, and verify that 657 colors are available:
  #+begin_src R
    head(colors())
    length(colors())
  #+end_src

  #+RESULTS:
  : [1] "white"         "aliceblue"     "antiquewhite"  "antiquewhite1"
  : [5] "antiquewhite2" "antiquewhite3"
  : [1] 657

- Instead of coloring all words with the same color, you can assign a
  vector of different colors to ~wordcloud~ to make certain words stand
  out or to fit a specific color scheme (e.g. to accommodate
  color-blind people).

- If you look at the ~wordcloud~ arguments:
  #+begin_src R
    <<load_packages>>
    args(wordcloud)
  #+end_src

  #+RESULTS:
  : function (words, freq, scale = c(4, 0.5), min.freq = 3, max.words = Inf, 
  :     random.order = TRUE, random.color = FALSE, rot.per = 0.1, 
  :     colors = "black", ordered.colors = FALSE, use.r.layout = FALSE, 
  :     fixed.asp = TRUE, ...) 
  : NULL

- The ~colors~ argument colors words from least to most frequent. The
  code uses three colors of increasing vibrancy - this will naturally
  divide the term frequency into "low", "medium", and "high":
  #+begin_src R :results graphics file :file ../img/wordcloud_color.png
    <<word_freq>>
    wordcloud(words=word_freq$term,
              freq=word_freq$num,
              max.words=100,
              colors=c("grey80","darkgoldenrod1","tomato"))
  #+end_src

  #+RESULTS:
  [[file:../img/wordcloud_color.png]]

  #+begin_src R
    str(word_freq)
  #+end_src

  #+RESULTS:
  : 'data.frame':	3067 obs. of  2 variables:
  :  $ term: chr  "chardonnay" "amp" "marvin" "wine" ...
  :  $ num : num  822 120 104 83 76 75 63 55 47 43 ...

* Using prebuilt color palettes: ~viridisLite~

- The ~viridisLite~ package contains color maps designed to improve
  graph readability for readers with color vision deficiencies.

- Also, the colors translate well into black-and-white versions
  without loss of readability.

- Install ~viridisLite~ in the R console, load it and check success:
  #+begin_src R
    library(viridisLite)
    search()
  #+end_src

- Look at the contents of the package with ~ls~: these are the different
  color maps.
  #+begin_src R
    ls('package:viridisLite')
  #+end_src

  #+RESULTS:
  :  [1] "cividis"     "inferno"     "magma"       "mako"        "plasma"     
  :  [6] "rocket"      "turbo"       "viridis"     "viridis.map" "viridisMap"

- All maps are functions with one mandatory argument, the number of
  colors ~n~ used. Check the arguments of ~viridisLite::cividis~:
  #+begin_src R
    args(cividis)
  #+end_src

  #+RESULTS:
  : function (n, alpha = 1, begin = 0, end = 1, direction = 1) 
  : NULL

- As the vignette for ~viridisLite~ reveals, the other parameter allow
  to change transparency (~alpha~), hue (~begin~ and ~end~), and
  order. Here are the color scales for the maps:
  #+attr_latex: :width 400px
  [[../img/8_viridis.png]]

- To created a new wordcloud with the selected palette, select 5
  colors from ~turbo~ and store them in a vector ~color_pal~:
  #+begin_src R :results silent
    color_pal <- turbo(5)
  #+end_src

- Print the hex-codes for ~color_pal~ to the console:
  #+begin_src R 
    color_pal
  #+end_src  

  #+RESULTS:
  : [1] "#30123BFF" "#28BBECFF" "#A2FC3CFF" "#FB8022FF" "#7A0403FF"

- Create a word cloud from the Chardonnay tweets ~word_freq~, include
  100 terms, and set the ~colors~ to the ~color_pal~ palette:
  #+begin_src R :results graphics file :file ../img/colorcloud.png
    wordcloud(words=word_freq$term,
              freq=word_freq$num,
              max.words=100,
              colors=color_pal)
  #+end_src

  #+RESULTS:
  [[file:../img/colorcloud.png]]

- 
  
* Load packages
#+name: load_packages
#+begin_src R
load_packages <- function() {
    library(tm)
    library(qdap)
    library(SnowballC)
    library(wordcloud)
    search()
}
load_packages()
#+end_src
* Footnotes

[fn:1] Funnily enough, I had no idea until I looked into the raw ~CSV~
file: ~amp~ is a remnant of ~&amp~ after ~removePunctuation~, and it's the
HTML short code for ~&~, which is frequent in tweets (saves 2
letters). As an interesting aside: I am already so dependent on
ChatGPT that instead of checking the data, I went and asked the bot
about "amp in the context of Chardonnay" but to no avail, of course.
