#+TITLE: Text mining in practice - Bag of Words - Intro to word networks
#+AUTHOR: Marcus Birkenkrahe
#+SUBTITLE: Digital Humanities DSC 105 Spring 2023
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README
#+begin_center
Time-stamp: <2023-03-30 08:51:10 Birkenkrahe>
#+end_center

- This lecture closely follows the DataCamp lesson "Text Mining with
  Bag-of-Words in R" by Ted Kwartler, chapter 2, lesson 3, "Other word
  clouds and word nets" ([[https://campus.datacamp.com/courses/text-mining-with-bag-of-words-in-r/][Link]]).

- Download and open the practice file ~9_wordnets_practice.org~ from
  GitHub to code along.

- In this lecture & practice:
  1) Finding and visualizing common words
  2) Creating a polarized tag cloud and pyramid plots
  3) Visualize word networks
  4) Visualizing word clusters as dendograms

* Get the corpus data and the R packages

- Load the ~.RData~ file [[https://bit.ly/tm_rdata][from GitHub]] (*bit.ly/tm_rdata*) in your current R
  session and check that packages and user-defined objects were
  loaded (load from the right location):
  #+begin_src R
    <<load_packages>>
    load("c:/Users/birkenkrahe/Downloads/.RData")
  #+end_src

- You need the ~clean_coffee~ and ~clean_chardonnay~ corpora:
  #+begin_src R
    ls()
  #+end_src

  #+RESULTS:
  #+begin_example
   [1] "api_key"                 "ask_chatgpt"            
   [3] "bar"                     "chardonnay_corpus"      
   [5] "chardonnay_df"           "chardonnay_src"         
   [7] "chardonnay_vec"          "clean_chardonnay"       
   [9] "clean_chardonnay_corpus" "clean_coffee"           
  [11] "clean_coffee_corpus"     "coffee_corpus"          
  [13] "coffee_df"               "coffee_src"             
  [15] "coffee_vec"              "convert_counts"         
  [17] "foo"                     "ham"                    
  [19] "load_packages"           "m"                      
  [21] "sms_classifier"          "sms_classifier_"        
  [23] "sms_classifier2"         "sms_corpus"             
  [25] "sms_corpus_clean"        "sms_dtm"                
  [27] "sms_dtm_freq_test"       "sms_dtm_freq_train"     
  [29] "sms_dtm_test"            "sms_dtm_train"          
  [31] "sms_dtm2"                "sms_freq_words"         
  [33] "sms_raw"                 "sms_test"               
  [35] "sms_test_labels"         "sms_test_pred"          
  [37] "sms_test_pred2"          "sms_train"              
  [39] "sms_train_labels"        "spam"                   
  [41] "string"                  "stringX"                
  [43] "text_df"                 "tokens"
  #+end_example

* Find common words

- We're going to use ~wordcloud::commonality.cloud~: the function
  requires a TDM of the terms from both datasets:
  #+begin_src R
    
  #+end_src

- Paste *coffee* tweets with ~collapse=" "~, look at structure of result
  with ~str~, and count characters with ~nchar~:
  #+begin_src R
    all_coffee <- paste()
    str()
    nchar()
  #+end_src

- Paste *Chardonnay* tweets with ~collapse=" "~, look at structure of result
  with ~str~, and count characters with ~nchar~:
  #+begin_src R
    all_chardonnay <- paste()
    str()
    nchar()
  #+end_src

- Combine all tweets from ~all_coffee~ and ~all_chardonnay~ in one vector
  ~all_tweets~, show structure and number of characters:
  #+begin_src R
    all_tweets <- c()
    str()
    nchar()
  #+end_src

- Create the corpus from vector and source with ~VectorSource~ and
  ~VCorpus~ and ~inspect~ it:
  #+begin_src R
    all_corpus <- 

  #+end_src

* Visualize common words with ~commonality.cloud~

- Clean the corpus by applying ~clean_corpus~ to ~all_corpus~
  #+name: all_clean
  #+begin_src R
    <<clean_corpus>>
    all_clean <- 

  #+end_src

- Create a TDM ~all_tdm~ for the corpus ~all_clean~:
  #+name: all_tdm
  #+begin_src R
    all_tdm <- 
  #+end_src

- Convert ~all_tdm~ to a ~matrix~ object ~all_m~ and display its structure:
  #+name: all_m
  #+begin_src R
    all_m <- 
  #+end_src

- Create a commonality cloud from ~all_m~ with ~max.words=100~ and
  ~colors="steelblue1"~:
  #+begin_src R :results graphics file :file commonality.png
    <<all_clean>>
    <<all_tdm>>
    <<all_m>>
    commonality.cloud()
  #+end_src

* Visualize dissimilar words with ~comparison.cloud~

- To visualize dissimilar words, you can use ~comparison.cloud~, which
  has quite a few more arguments:
  #+begin_src R

  #+end_src

- Clean the corpus, create TDM:
  #+begin_src R
    <<all_clean>>
    <<all_tdm>>
  #+end_src

- The ~tdm~ is organized neatly in two columns:
  #+begin_src R
    as.matrix()
  #+end_src

- Use ~colnames~ to rename each distinct corpora within ~all_tdm~ so that
  we can keep track of the contributions from either corpus:
  #+name: colnames
  #+begin_src R
    colnames(all_tdm) <-
    as.matrix()
  #+end_src

  #+RESULTS:
  :            Docs
  : Terms       coffee chardonnay
  :   asia           1          0
  :   asian          1          1
  :   ask            6          4
  :   asked          3          1
  :   asking         0          6
  :   askorange      2          0

- Create a matrix ~all_m~ from ~all_tdm~:
  #+begin_src R
    all_m <- 
  #+end_src

- Create a comparison cloud with ~max.words=50~ and the ~colors~ "orange"
  and "blue":
  #+begin_src R :results graphics file :file comparisoncloud.png
    <<all_clean>>
    <<all_tdm>>
    <<colnames>>
    comparison.cloud()
  #+end_src

* Compare word commonality with ~pyramid_plot~

- We want to see which common words appear more often in which
  dataset: the ~pyramid.plot~ from the ~plotrix~ package delivers an
  aligned bargraph that shows this:
  1) (install and) load the ~plotrix~ package
  2) Which methods does ~plotrix~ have?
  3) show the arguments of the ~pyramid.plot~ function
  #+begin_src R

  #+end_src

- Data transformation: we need a data frame with three columns, the
  words contained in each document, and the counts from each:
  1) Coerce ~all_m~ to a "tibble" (a special type of data frame)
  2) ~filter~ all words with non-zero frequency in either dataset
  3) add a ~difference~ column with the difference in counts by word
  4) extract those records with more than 25 counts difference
  5) arrange the records in descending order
  #+begin_src R :results silent
    library(dplyr)
    top25_df <- all_m %>%
      ## Convert to data frame
      as_tibble(rownames = "word") %>% 
      ## Keep rows where word appears everywhere
      filter(if_all(everything(), ~. > 0)) %>% 
      ## Get difference in counts
      mutate(difference = chardonnay - coffee) %>% 
      ## Keep rows with biggest difference
      slice_max(difference,  n = 25) %>% 
      ## Arrange by descending difference
      arrange(desc(difference))
  #+end_src

- To create the pyramid plot,
  1) set the left count to the ~chardonnay~ column
  2) set the right count to the ~coffee~ column
  3) set the labels to the ~word~ column
  #+begin_src R :results graphics file :file pyramidplot.png
    pyramid.plot(
      ## Chardonnay counts
      top25_df$chardonnay, 
      ## Coffee counts
      top25_df$coffee, 
      ## Words
      labels = top25_df$word, 
      top.labels = c("Chardonnay", "Words", "Coffee"), 
      main = "Words in Common", 
      unit = NULL,
      gap = 8, )
  #+end_src
  
* Visualize word networks

- This code constructs a word network for words associated with
  "Marvin", a dominant word in the Chardonnay tweets:
  #+begin_src R :results graphics file :file marvinnet.png
    ## Word association
    word_associate(
                   match.string = 
                   stopwords = 
                   network.plot = 
                   cloud.colors =
                     )
    ## Add title
    title(main = "Chardonnay Tweets Associated with Marvin")
  #+end_src

- To get the printed output information, run the code block again
  without graphics - the graph will open in a separate window.
  
- This code constructs a word network for words associated with
  "barista", a word in the coffee tweets:
  #+begin_src R :results graphics file :file baristanet.png
    ## Word association
    word_associate(coffee_df$text,
                   match.string = 
                   stopwords = c(Top200Words, "coffee", "amp"), 
                   network.plot = TRUE,
                   cloud.colors = c("gray85", "darkred"))
    ## Add title
    title(main = "Barista Coffee Tweet Associations")
  #+end_src
  
* Resources
** ~load_packages~
#+name: load_packages
#+begin_src R
  load_packages <- function() {
    library(tm)
    library(qdap)
    library(SnowballC)
    library(wordcloud)
    search()
  }
  load_packages()
#+end_src
** ~clean_corpus~
#+name: clean_corpus
#+begin_src R
  clean_corpus <- function(corpus) {
    corpus <- tm_map(corpus,
                     removeNumbers)
    corpus <- tm_map(corpus,
                     removePunctuation)
    corpus <- tm_map(corpus,
                     content_transformer(tolower))
    corpus <- tm_map(corpus,
                     removeWords,
                     words = c(stopwords("en"),"coffee","beans",
                               "can", "hgtv","bean", "chardonnay",
                               "glass","glasses","wine","amp","just"))
    corpus <- tm_map(corpus,
                     stripWhitespace)
    return(corpus)
  }
#+end_src

#+RESULTS:
