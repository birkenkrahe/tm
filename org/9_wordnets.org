#+TITLE: Text mining in practice - Bag of Words - Intro to word networks
#+AUTHOR: Marcus Birkenkrahe
#+SUBTITLE: Digital Humanities DSC 105 Spring 2023
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README
#+begin_center
Time-stamp: <2023-03-30 08:51:10 Birkenkrahe>
#+end_center

- This lecture closely follows the DataCamp lesson "Text Mining with
  Bag-of-Words in R" by Ted Kwartler, chapter 2, lesson 3, "Other word
  clouds and word nets" ([[https://campus.datacamp.com/courses/text-mining-with-bag-of-words-in-r/][Link]]).

- Download and open the practice file ~9_wordnets_practice.org~ from
  GitHub to code along.

- In this lecture & practice:
  1) Finding and visualizing common words
  2) Creating a polarized tag cloud and pyramid plots
  3) Visualize word networks
  4) Visualizing word clusters as dendograms

* Get the corpus data and the R packages

- Load the ~.RData~ file [[https://bit.ly/tm_rdata][from GitHub]] (*bit.ly/tm_rdata*) in your current R
  session and check that packages and user-defined objects were
  loaded (load from the right location):
  #+begin_src R
    <<load_packages>>
    load("c:/Users/birkenkrahe/Downloads/.RData")
  #+end_src

  #+RESULTS:
  #+begin_example
   [1] ".GlobalEnv"               "package:SnowballC"       
   [3] "package:gmodels"          "package:e1071"           
   [5] "package:tm"               "package:NLP"             
   [7] "package:qdap"             "package:qdapTools"       
   [9] "package:qdapRegex"        "package:qdapDictionaries"
  [11] "package:wordcloud"        "package:RColorBrewer"    
  [13] "ESSR"                     "package:stats"           
  [15] "package:graphics"         "package:grDevices"       
  [17] "package:utils"            "package:datasets"        
  [19] "package:stringr"          "package:httr"            
  [21] "package:methods"          "Autoloads"               
  [23] "package:base"
  #+end_example

- You need the ~clean_coffee~ and ~clean_chardonnay~ corpora:
  #+begin_src R
    ls()
  #+end_src

  #+RESULTS:
  #+begin_example
   [1] "api_key"                 "ask_chatgpt"            
   [3] "bar"                     "chardonnay_corpus"      
   [5] "chardonnay_df"           "chardonnay_src"         
   [7] "chardonnay_vec"          "clean_chardonnay"       
   [9] "clean_chardonnay_corpus" "clean_coffee"           
  [11] "clean_coffee_corpus"     "coffee_corpus"          
  [13] "coffee_df"               "coffee_src"             
  [15] "coffee_vec"              "convert_counts"         
  [17] "foo"                     "ham"                    
  [19] "load_packages"           "m"                      
  [21] "sms_classifier"          "sms_classifier2"        
  [23] "sms_corpus"              "sms_corpus_clean"       
  [25] "sms_dtm"                 "sms_dtm_freq_test"      
  [27] "sms_dtm_freq_train"      "sms_dtm_test"           
  [29] "sms_dtm_train"           "sms_dtm2"               
  [31] "sms_freq_words"          "sms_raw"                
  [33] "sms_test"                "sms_test_labels"        
  [35] "sms_test_pred"           "sms_test_pred2"         
  [37] "sms_train"               "sms_train_labels"       
  [39] "spam"                    "string"                 
  [41] "stringX"                 "tokens"
  #+end_example

* The workflow

We're looking at two corpora at a time to find out which words they
have in common (the intersection), and which words they do not have in
common (the disjoint). To do this, we must:

1. Paste datasets
2. Collapse datasets into one
3. Make clean corpus
4. Make TDM
5. Make term matrix
6. Visualize term matrix

* Common and disjoint word sets

- Think of your corpora as sets and visualize them in Venn diagrams
  #+attr_latex: :width 400px
  #+caption: Visualizing common words as Venn diagram
  [[../img/dc_commonality_clouds1.png]]
  #+attr_latex: :width 400px
  #+caption: Visualizing comparison of disjoint words as Venn diagram
  [[../img/dc_comparison_cloud1.png]]

* Find common words

- We're going to use ~wordcloud::commonality.cloud~: the function
  requires a TDM of the terms from both datasets:
  #+begin_src R
    library(wordcloud)
    args(commonality.cloud)
  #+end_src

  #+RESULTS:
  : function (term.matrix, comonality.measure = min, max.words = 300, 
  :     ...) 
  : NULL

- Use ~paste~ with ~collapse=" "~ to separate the tweets in both data
  frames containing the tweets, ~coffee_df~ and ~chardonnay_df~.

- Paste coffee tweets, look at structure of result, count characters:
  #+begin_src R
    all_coffee <- paste(coffee_df$text, collapse=" ")
    str(all_coffee)
    nchar(all_coffee)
  #+end_src

  #+RESULTS:
  :  chr "@ayyytylerb that is so true drink lots of coffee RT @bryzy_brib: Senior March tmw morning at 7:25 A.M. in the S"| __truncated__
  : [1] 88230

- Paste Chardonnay tweets, look at structure, count characters:
  #+begin_src R
    all_chardonnay <- paste(chardonnay_df$text, collapse=" ")
    str(all_chardonnay)
    nchar(all_chardonnay)
  #+end_src

  #+RESULTS:
  :  chr "RT @oceanclub: @eilisohanlon @stonyjim @vonprond Eilis, I'm from Pearse St and even I can tell a Chardonnay (sm"| __truncated__
  : [1] 96880

- Combine all tweets from ~all_coffee~ and ~all_chardonnay~ in one vector
  ~all_tweets~, show structure and number of characters:
  #+begin_src R
    all_tweets <- c(all_coffee, all_chardonnay)
    str(all_tweets)
    nchar(all_tweets)
  #+end_src

  #+RESULTS:
  :  chr [1:2] "@ayyytylerb that is so true drink lots of coffee RT @bryzy_brib: Senior March tmw morning at 7:25 A.M. in the S"| __truncated__ ...
  : [1] 88230 96880

- Create the corpus from vector and source and ~inspect~ it:
  #+begin_src R
    all_corpus <- VCorpus(VectorSource(all_tweets))
    inspect(all_corpus)
  #+end_src

  #+RESULTS:
  #+begin_example
  <<VCorpus>>
  Metadata:  corpus specific: 0, document level (indexed): 0
  Content:  documents: 2

  [[1]]
  <<PlainTextDocument>>
  Metadata:  7
  Content:  chars: 88230

  [[2]]
  <<PlainTextDocument>>
  Metadata:  7
  Content:  chars: 96880
  #+end_example

* Visualize common words with ~commonality.cloud~

- You need to clean the corpus, create a TDM that you can then
  visualize using ~commonality.cloud~ from the ~wordcloud~ package

- Clean the corpus by applying ~clean_corpus~ to ~all_corpus~
  #+name: all_clean
  #+begin_src R
    <<clean_corpus>>
    all_clean <- clean_corpus(all_corpus)
    inspect(all_clean)
  #+end_src

  #+RESULTS: all_clean
  #+begin_example
  <<VCorpus>>
  Metadata:  corpus specific: 0, document level (indexed): 0
  Content:  documents: 2

  [[1]]
  <<PlainTextDocument>>
  Metadata:  7
  Content:  chars: 55271

  [[2]]
  <<PlainTextDocument>>
  Metadata:  7
  Content:  chars: 57999
  #+end_example


- Create a TDM ~all_tdm~ for the corpus ~all_clean~:
  #+name: all_tdm
  #+begin_src R
    all_tdm <- TermDocumentMatrix(all_clean)
    all_tdm
  #+end_src

  #+RESULTS: all_tdm
  : <<TermDocumentMatrix (terms: 5406, documents: 2)>>
  : Non-/sparse entries: 6089/4723
  : Sparsity           : 44%
  : Maximal term length: 266
  : Weighting          : term frequency (tf)

- Convert ~all_tdm~ to a ~matrix~ object ~all_m~
  #+name: all_m
  #+begin_src R
    all_m <- as.matrix(all_tdm)
    str(all_m)
  #+end_src

  #+RESULTS: all_m
  :  num [1:5406, 1:2] 0 1 1 1 1 1 1 1 1 1 ...
  :  - attr(*, "dimnames")=List of 2
  :   ..$ Terms: chr [1:5406] "aaliyahmaxwell" "abasc" "abbslovesfed" "abbycastro" ...
  :   ..$ Docs : chr [1:2] "1" "2"

  #+begin_src R
    args(commonality.cloud)
  #+end_src

  #+RESULTS:
  : function (term.matrix, comonality.measure = min, max.words = 300, 
  :     ...) 
  : NULL

- Create a commonality cloud from ~all_m~ with ~max.words=100~ and
  ~colors="steelblue1"~:
  #+begin_src R :results graphics file :file ../img/commonality.png
    <<all_clean>>
    <<all_tdm>>
    <<all_m>>
    commonality.cloud(term.matrix=all_m,
                      max.words=100,
                      colors="steelblue1",
                      random.order=TRUE)
  #+end_src

  #+RESULTS:
  [[file:../img/commonality.png]]

* Visualize dissimilar words with ~comparison.cloud~

- To visualize dissimilar words, you can use ~comparison.cloud~, which
  has quite a few more arguments:
  #+begin_src R
    args(comparison.cloud)
  #+end_src

  #+RESULTS:
  : function (term.matrix, scale = c(4, 0.5), max.words = 300, random.order = FALSE, 
  :     rot.per = 0.1, colors = brewer.pal(max(3, ncol(term.matrix)), 
  :         "Dark2"), use.r.layout = FALSE, title.size = 3, title.colors = NULL, 
  :     match.colors = FALSE, title.bg.colors = "grey90", ...) 
  : NULL


- Clean the corpus, create TDM:
  #+begin_src R
    <<all_clean>>
    <<all_tdm>>
  #+end_src

- The ~tdm~ is organized neatly in two columns:
  #+begin_src R
    as.matrix(all_tdm)[200:205,]
  #+end_src

  #+RESULTS:
  :            Docs
  : Terms       1 2
  :   asia      1 0
  :   asian     1 1
  :   ask       6 4
  :   asked     3 1
  :   asking    0 6
  :   askorange 2 0

- Use ~colnames~ to rename each distinct corpora within ~all_tdm~ so that
  we can keep track of the contributions from either corpus:
  #+name: colnames
  #+begin_src R
    colnames(all_tdm) <- c("coffee","chardonnay")
    as.matrix(all_tdm)[400:405,]
  #+end_src

  #+RESULTS: colnames
  :              Docs
  : Terms         coffee chardonnay
  :   bittersweet      1          0
  :   bjs              0          1
  :   black           10          7
  :   blackboard       1          0
  :   blanc            0          6
  :   blankets         1          0

- Create a matrix ~all_m~ from ~all_tdm~:
  #+begin_src R
    all_m <- as.matrix(all_tdm)
    all_m[400:405,]
  #+end_src

  #+RESULTS:
  :              Docs
  : Terms         coffee chardonnay
  :   bittersweet      1          0
  :   bjs              0          1
  :   black           10          7
  :   blackboard       1          0
  :   blanc            0          6
  :   blankets         1          0

  
- Create a comparison cloud with ~max.words=50~ and the ~colors~ "orange"
  and "blue":
  #+begin_src R :results graphics file :file ../img/comparisoncloud.png
    <<all_clean>>
    <<all_tdm>>
    <<colnames>>
    comparison.cloud(term.matrix=all_m,
                     max.words=50,
                     colors=c("orange","blue"))
  #+end_src

  #+RESULTS:
  [[file:../img/comparisoncloud.png]]

* Compare word commonality with ~pyramid_plot~

- We want to see which common words appear more often in which
  dataset: the ~pyramid.plot~ from the ~plotrix~ package delivers an
  aligned bargraph that shows this:
  #+begin_src R
    library(plotrix)
    args(pyramid.plot)
  #+end_src

  #+RESULTS:
  : function (lx, rx, labels = NA, top.labels = c("Male", "Age", 
  :     "Female"), main = "", laxlab = NULL, raxlab = NULL, unit = "%", 
  :     lxcol, rxcol, gap = 1, space = 0.2, ppmar = c(4, 2, 4, 2), 
  :     labelcex = 1, add = FALSE, xlim, show.values = FALSE, ndig = 1, 
  :     do.first = NULL) 
  : NULL

- Data transformation: we need a data frame with three columns, the
  words contained in each document, and the counts from each:
  1) Coerce ~all_m~ to a "tibble" (a special type of data frame)
  2) ~filter~ all words with non-zero frequency in either dataset
  3) add a ~difference~ column with the difference in counts by word
  4) extract those records with more than 25 counts difference
  5) arrange the records in descending order
  #+begin_src R :results silent
    library(dplyr)
    top25_df <- all_m %>%
      ## Convert to data frame
      as_tibble(rownames = "word") %>% 
      ## Keep rows where word appears everywhere
      filter(if_all(everything(), ~. > 0)) %>% 
      ## Get difference in counts
      mutate(difference = chardonnay - coffee) %>% 
      ## Keep rows with biggest difference
      slice_max(difference,  n = 25) %>% 
      ## Arrange by descending difference
      arrange(desc(difference))
  #+end_src

- To create the pyramid plot,
  1) set the left count to the ~chardonnay~ column
  2) set the right count to the ~coffee~ column
  3) set the labels to the ~word~ column
  #+begin_src R :results graphics file :file ../img/pyramidplot.png
    pyramid.plot(
      ## Chardonnay counts
      top25_df$chardonnay, 
      ## Coffee counts
      top25_df$coffee, 
      ## Words
      labels = top25_df$word, 
      top.labels = c("Chardonnay", "Words", "Coffee"), 
      main = "Words in Common", 
      unit = NULL,
      gap = 8,
      )
  #+end_src

  #+RESULTS:
  [[file:../img/pyramidplot.png]]
  
* Visualize word networks

- Word networks show term association (with a link) and cohesion
  (neighborhoods and density of links), like a social network.

- In a network graph, the circles are called /nodes/ and represent
  individual terms, while the lines connecting the circles are called
  /edges/ and represent the connections between the terms.

- The ~qdap~ package contains ~word_network_plot~ and ~word_associate~ to
  create word networks.

- This code constructs a word network for words associated with
  "Marvin", a dominant word in the Chardonnay tweets:
  #+begin_src R :results graphics file :file ../img/marvinnet.png
    ## Word association
    word_associate(chardonnay_df$text,
                   match.string = "marvin", 
                   stopwords = c(Top200Words, "chardonnay", "amp"), 
                   network.plot = TRUE,
                   cloud.colors = c("gray85", "darkred"))
    ## Add title
    title(main = "Chardonnay Tweets Associated with Marvin")
  #+end_src

  #+RESULTS:
  [[file:../img/marvinnet.png]]

- To get the printed output information, run the code block again
  without graphics - the graph will open in a separate window:
  #+begin_src R 
    ## Word association
    word_associate(chardonnay_df$text,
                   match.string = "marvin", 
                   stopwords = c(Top200Words, "chardonnay", "amp"), 
                   network.plot = TRUE,
                   cloud.colors = c("gray85", "darkred"))
    ## Add title
    title(main = "Chardonnay Tweets Associated with Marvin")
  #+end_src
  
- This code constructs a word network for words associated with
  "barista", a word in the coffee tweets:
  #+begin_src R :results graphics file :file ../img/baristanet.png
    ## Word association
    word_associate(coffee_df$text,
                   match.string = "barista", 
                   stopwords = c(Top200Words, "coffee", "amp"), 
                   network.plot = TRUE,
                   cloud.colors = c("gray85", "darkred"))
    ## Add title
    title(main = "Barista Coffee Tweet Associations")
  #+end_src

  #+RESULTS:
  [[file:../img/baristanet.png]]
  
* Resources
** ~load_packages~
#+name: load_packages
#+begin_src R
  load_packages <- function() {
    library(tm)
    library(qdap)
    library(SnowballC)
    library(wordcloud)
    search()
  }
  load_packages()
#+end_src
** ~clean_corpus~
#+name: clean_corpus
#+begin_src R
  clean_corpus <- function(corpus) {
    corpus <- tm_map(corpus,
                     removeNumbers)
    corpus <- tm_map(corpus,
                     removePunctuation)
    corpus <- tm_map(corpus,
                     content_transformer(tolower))
    corpus <- tm_map(corpus,
                     removeWords,
                     words = c(stopwords("en"),"coffee","beans",
                               "can", "hgtv","bean", "chardonnay",
                               "glass","glasses","wine","amp","just"))
    corpus <- tm_map(corpus,
                     stripWhitespace)
    return(corpus)
  }
#+end_src

#+RESULTS:
