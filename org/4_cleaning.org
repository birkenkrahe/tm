#+TITLE: Text mining in practice - Bag of Words - data cleaning
#+AUTHOR: Marcus Birkenkrahe
#+SUBTITLE: Digital Humanities DSC 105 Spring 2023
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README
#+attr_latex: :width 400px
[[../img/4_cleaning.jpg]]

- This lecture closely follows the 3rd part of the DataCamp lesson
  "Jumping into Text Minin with Bag-of-Words" by Ted Kwartler, part of
  his course on [[https://campus.datacamp.com/courses/text-mining-with-bag-of-words-in-r/]["Text Mining with Bag-of-Words in R"]].

- Download and open the practice file ~4_cleaning_practice.org~ from
  GitHub to code along.

* Cleaning and preprocessing text

- Base R cleaning functions:
  #+attr_html: :width 400px
  #+caption: Text mining functions
  [[../img/4_clean.png]]

  #+begin_src R
    tolower("WHATSHAPPENING")
  #+end_src

  Is ~tm~ loaded?
  #+begin_src R
    library(tm)
    search()
  #+end_src

  #+RESULTS:
  : Loading required package: NLP
  :  [1] ".GlobalEnv"        "package:tm"        "package:NLP"      
  :  [4] "ESSR"              "package:stats"     "package:graphics" 
  :  [7] "package:grDevices" "package:utils"     "package:datasets" 
  : [10] "package:methods"   "Autoloads"         "package:base"

* Create sample corpus

- Create corpus so we have something to work with:
  #+begin_src R :results silent
    library(tm)
    coffee_df <- read.csv("../data/coffee.csv") # dataframe
    coffee_vec <- coffee_df$text # vector
    coffee_src <- VectorSource(coffee_vec) # source
    coffee_corpus <- VCorpus(coffee_src)
  #+end_src
* Invoke functions separately
- Each function separately:
  #+begin_src R
    t <- coffee_corpus[[2]]
    content(t)
    tolower(t)
    content(removePunctuation(t)) 
    content(removeNumbers(t))
    stripWhitespace("There      is    a     lot    of space    .")
    content(removeWords(t, c("in", "the", "at")))
  #+end_src

  #+RESULTS:
  : [1] "RT @bryzy_brib: Senior March tmw morning at 7:25 A.M. in the SENIOR lot. Get up early, make yo coffee/breakfast, cus this will only happen ?"
  : [1] "rt @bryzy_brib: senior march tmw morning at 7:25 a.m. in the senior lot. get up early, make yo coffee/breakfast, cus this will only happen ?"
  : [1] "RT bryzybrib Senior March tmw morning at 725 AM in the SENIOR lot Get up early make yo coffeebreakfast cus this will only happen "
  : [1] "RT @bryzy_brib: Senior March tmw morning at : A.M. in the SENIOR lot. Get up early, make yo coffee/breakfast, cus this will only happen ?"
  : [1] "There is a lot of space ."
  : [1] "RT @bryzy_brib: Senior March tmw morning  7:25 A.M.   SENIOR lot. Get up early, make yo coffee/breakfast, cus this will only happen ?"

* Nest functions
- Nested functions:
  #+begin_src R
    content(t)
    tc <-
      tolower(
        content(
          removePunctuation(
            removeNumbers(
              removeWords(t, c("in", "the", "at", "will", "only", "this"))))))
    tc
  #+end_src
* Create a pipeline of functions with ~|>~
- Function pipeline
  #+begin_src R
    content(t)
    t |>
      removeWords(c("in", "the", "at", "this", "will", "only"))  |>
      removeNumbers() |>
      removePunctuation() |>
      content() |>
      tolower()
  #+end_src
* Apply function with the ~tm_map~ wrapper
- Apply functions to the whole corpus with the ~tm_map~ wrapper:
  #+begin_src R
    ## run functions as an argument to tm_map
    tm_map(coffee_corpus, removeNumbers) -> cc_no_numbers
    tm_map(coffee_corpus, removePunctuation) -> cc_no_punctuation
    ## check content
    content(cc_no_numbers[[2]])
    content(cc_no_punctuation[[2]])
  #+end_src

- These functions live in different environments:
  #+begin_src R
    library(tm)
    library(qdap)
    environment(tolower)
    environment(removePunctuation)
    environment(removeNumbers)
    environment(removeWords)
    environment(stripWhitespace)
    environment(replace_abbreviation)
  #+end_src

- To work, ~tm_map~ must transform a function from another package with
  ~content_transformer~ (this also takes a lot longer):
  #+begin_src R
    library(tm)
    library(qdap)
    ## where is replace_abbreviation?
    environment(replace_abbreviation)
    ## run this function with tm_map - store result in repl
    tm_map(coffee_corpus, content_transformer(replace_abbreviation)) -> repl
    ## print content with and without abbrevs replaced
    content(coffee_corpus[[2]])
    content(repl[[2]])
  #+end_src
* Word stemming with ~stemDocument~

- Word stemming with ~tm::stemDocument~: requires installing ~SnowballC~:
  #+begin_src R
    library(qdap)
    library(SnowballC)
    stem_words <- stemDocument(c("complicatedly",
                                 "complicated",
                                 "complication",
                                 "complicate"))
    stem_words
  #+end_src

- Interestingly, the stem of ~Complicate~ is recognized, but not the
  stem of ~ComplicatE~ or ~COMPLICATE~.

* Completing word stems with ~stemCompletion~

- You can complete the words using a single word dictionary (i.e. all
  stems are mapped onto a single word):
  #+begin_src R
    stemCompletion(stem_words, c("complicate"))
  #+end_src

- You can use a corpus as completion dictionary:
  #+begin_src R
    stemCompletion(stem_words, coffee_corpus)
  #+end_src

- ~coffee_corpus~ does not contain a matching word!

- Create a new corpus just for ~stem_words~ to test the function
  ~stemCompletion~, starting with the vector ~c("complicate")~:
  #+begin_src R
    my_vec <- c("complicate")
    my_src <- VectorSource(my_vec)
    my_corpus <- VCorpus(my_src)
    stemCompletion(stem_words, my_corpus)
  #+end_src

* Full-text corpus data online

- One can look for
  "full-text corpus data" online ([[https://www.corpusdata.org/][link]]) - it's fast but you only have
  a limited number of (free) searches per day.
  #+attr_html: :width 400px
  #+caption: English language corpora (english-corpora.org)
  [[../img/4_corpora.png]]
  #+attr_html: :width 400px
  #+caption: Google Books corpora - search example "Marxism"
  [[../img/4_corpora1.png]]
  #+attr_html: :width 400px
  #+caption: Google Books corpora - search example "Marxism" - results
  [[../img/4_corpora2.png]]
  #+attr_html: :width 400px
  #+caption: Google Books corpora - search example "Marxism" - results
  [[../img/4_corpora3.png]]

- What's interesting about this: "Marxism" relates to Karl Marx, who
  came up with his theories in the 1840s. How then could "marxism" be
  mentioned in books published before that date?

* NEXT Cleaning with ~qdap~

- To see the full range of arguments of a function, pass the function
  name as an argument to ~args()~ - e.g. for ~qdap::bracketX~:
  #+begin_src R
    library(qdap)
    args(bracketX)
  #+end_src

- To find out more, e.g. about the options for the parameter ~bracket~,
  look at the ~help~ page (when you do this in an Emacs Org-mode code
  block, interrupt the process manually with ~C-g~ to go on).
  #+begin_src R
    help(bracketX)
  #+end_src

* Text cleaning functions in ~qdap~

- The ~qdap~ package offers other text cleaning functions:

  + ~bracketX()~: Remove all text within brackets (e.g. "It's (so) cool"
    becomes "It's cool", "<b>Yes</b>" becomes "Yes")
  + ~replace_number()~: Replace numbers with their word equivalents
    (e.g. "2" becomes "two")
  + ~replace_abbreviation()~: Replace abbreviations with their full text
    equivalents (e.g. "Sr" becomes "Senior")
  + ~replace_contraction()~: Convert contractions back to their base words
    (e.g. "shouldn't" becomes "should not")
  + ~replace_symbol()~: Replace common symbols with their word
    equivalents (e.g. "$" becomes "dollar")

* Test text cleaning functions in ~qdap~

- Define a sample text vector:
  #+begin_src R
    ## define text vector
    text <-
      "<b>She</b> woke up at       6 A.M. It\'s so
       early!  She was only 10% awake and began drinking
       coffee in front of her computer."
    text
  #+end_src
- Remove text within brackets:
  #+begin_src R
    text
    bracketX(text)
  #+end_src
- Replace all numbers with words:
  #+begin_src R
    text
    replace_number(text)
  #+end_src
- Replace abbreviations:
  #+begin_src R
    text
    replace_abbreviation(text)
  #+end_src
- Replace contractions:
  #+begin_src R
    text
    replace_contraction(text)
  #+end_src
- Replace symbols with words:
  #+begin_src R
    text
    replace_symbol(text)
  #+end_src
- Run all of these on ~text~ together using a pipeline ~|>~:
  #+begin_src R
    text |>
      bracketX() |>
      replace_number() |>
      replace_abbreviation() |>
      replace_contraction() |>
      replace_symbol()
  #+end_src

