#+TITLE: Sentiment analysis in R - Polarity Scoring - Exercises
#+AUTHOR: [YourName & pledge]
#+SUBTITLE: Digital Humanities DSC 105 Spring 2023
#+STARTUP:overview hideblocks indent inlineimages
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README

The source for these exercises is Kwartler T (2019). Sentiment
Analysis in R. URL: datacamp.com.

* Exercise: manual ~polarity~ scoring

- ~polarity~ scans the text to identify words in the lexicon. It then
  creates a /cluster/ around an identified /subjectivity word/. Within the
  cluster /valence shifters/ adjust the score.

- Valence shifters are words that amplify or negate the emotional
  intent of the subjectivity word. For example, "well known" is
  positive while "not well known" is negative. Here "not" is a
  negating term and reverses the emotional intent of "well known." In
  contrast, "very well known" employs an /amplifier/ increasing the
  positive intent.

- The ~polarity~ function then calculates a score using subjectivity
  terms, valence shifters and the total number of words in the
  passage. This exercise demonstrates a simple polarity calculation.

1) Calculate the ~polarity~ of the string ~positive~ in a new object
   called ~pos_score~, then print it:
   #+begin_src R
     positive <- "DataCamp courses are good for learning"
     ## Calculate polarity of statement

   #+end_src

   #+RESULTS:

2) Manually perform the same polarity calculation:

   1. Get a word count object ~pos_counts~ by calling ~counts~ on the polarity
      object ~pos_score~, then print it:
      #+begin_src R

      #+end_src

      #+RESULTS:

   2. All the identified subjectivity words are part of count object's
      list. Specifically, positive words are in the ~$pos.words~ element
      vector of ~pos_counts~. Print the structure of ~pos_counts~:
      #+begin_src R

      #+end_src

      #+RESULTS:

   3. Find the number of positive words by calling ~length~ on the first
      member of the ~$pos_words~ element of ~pos_counts~ and store it in
      ~n_good~:
      #+begin_src R :results silent

      #+end_src

   4. Capture the total number of words and assign it to ~n_words~. This
      value is stored in ~pos_count~ as the ~wc~ (word count) element:
      #+begin_src R :results silent

      #+end_src

   5. De-construct the ~polarity~ calculation by dividing ~n_good~ by ~sqrt~
      of ~n_words~ and save the result as ~pos_pol~. Compare ~pos_pol~ to
      ~pos_score~ calculated with ~polarity~ earlier using ~identical~:
      #+begin_src R

      #+end_src

      #+RESULTS:

* Exercise: apply valence shifters

- Of course just positive and negative words aren't enough. In this
  exercise you will learn about valence shifters which tell you about
  the author's emotional intent. Previously you applied ~polarity()~ to
  text without valence shifters. In this example you will see
  amplification and negation words in action.

- Recall that an amplifying word adds 0.8 to a positive word in
  ~polarity()~ so the positive score becomes 1.8. For negative words 0.8
  is subtracted so the total becomes -1.8. Then the score is divided
  by the square root of the total number of words.

- Consider the following example from Frank Sinatra:
  #+begin_example R
    "It was a very good year"
  #+end_example
  "Good" equals 1 and "very" adds another 0.8. So, 1.8/sqrt(6) results
  in 0.73 polarity.

- A negating word such as "not" will inverse the subjectivity
  score. Consider the following example from Bobby McFerrin:
  #+begin_src R
    "Don't worry Be Happy"
  #+end_src
  "worry is now 1 due to the negation "don't." Adding the "happy", +1,
  equals 2. With 4 total words, 2 / sqrt(4) equals a polarity score
  of 1.

-----
1) Load the ~conversation~ data frame and display its structure:
   #+begin_src R
     conversation <- data.frame( "student"=c("Martijn","Nick","Nicole"),
                                "text"=c("This restaurant is never bad", "The lunch was very good",
                                         "It was awful I got food poisoning and was extremely ill"))

   #+end_src

2) Examine the ~conversation~ data frame by printing it.
   #+begin_src R

   #+end_src

3) What context cluster category is "never"?
   #+begin_quote
   Answer: ...
   #+end_quote

4) Apply ~polarity()~ to the text column of conversation to calculate
   the polarity for the entire conversation:
   #+begin_src R

   #+end_src

5) Calculate the polarity scores for the ~text~ by ~student~ using the
   ~grouping.var~ argument, and assign the result to ~student_pol~:
   #+begin_src R

   #+end_src

8) To see the ~student~ level results, use ~scores()~ on ~student_pol~:
   #+begin_src R

   #+end_src

9) The ~counts()~ function applied to ~student_pol~ will print the
   sentence level polarity for the entire data frame along with
   lexicon words identified:
   #+begin_src R

   #+end_src

10) The polarity object, ~student_pol~, can be plotted with ~plot()~:
    #+begin_src R :results graphics file :file ../img/student_pol.png

    #+end_src

* Exercise: examine and use ~qdap~'s lexicon

- Even with Zipf's law in action, you will still need to adjust
  lexicons to fit the text source (for example twitter versus legal
  documents) or the author's demographics (teenager versus the
  elderly). This exercise demonstrates the explicit components of
  ~polarity()~ so you can change it if needed.

- In Trey Songz "Lol :)" song there is a lyric "LOL smiley face, LOL
  smiley face." In the basic ~polarity()~ function, "LOL" is not defined
  as positive. However, "LOL" stands for "Laugh Out Loud" and should
  be positive. As a result, you should adjust the lexicon to fit the
  text's context which includes pop-culture slang. If your analysis
  contains text from a specific channel (Twitter's "LOL"), location
  (Boston's "Wicked Good"), or age group (teenagers' "sick") you will
  likely have to adjust the lexicon.

- In the first exercise, you are examining the existing word data
  frame objects so you can change them in the following exercise.

-----

1) As a sample text, here are two excerpts from BeyoncÃ©'s "Crazy in
   Love" lyrics for the exercise - run the code and print the data
   frame's structure:
   #+begin_src R
     text <- data.frame(
       "speaker"=c("beyonce","jay_z"),
       "words"=c("I know I dont understand Just how your love can do what no one else can",
                 "They cant figure him out they like hey, is he insane"))

   #+end_src

2) Print ~qdapDictionaries::key.pol~ to see a portion of the subjectivity
   words and values:
   #+begin_src R

   #+end_src

3) Examine the predefined ~negation.words~ to print all the negating terms:
   #+begin_src R

   #+end_src

4) Print the amplifiers in ~amplification.words~ to see the words that
   add values to the lexicon:
   #+begin_src R

   #+end_src

5) Check the ~deamplification.words~ that reduce the lexicon values:
   #+begin_src R

   #+end_src

6) Now, calculate the ~polarity~ of ~text~ as follows and save it in ~text_pol~:
   1. Set ~text.var~ to ~text$words~.
   2. Set ~grouping.var~ to ~text$speaker~.
   3. Set ~polarity.frame~ to ~key.pol~.
   4. Set ~negators~ to ~negation.words~.
   5. Set ~amplifiers~ to ~amplification.words~.
   6. Set ~deamplifiers to deamplification.words~.
   #+begin_src R

   #+end_src

7) Print the positive and negative words alongside the ~text~ with the
   ~all~ element of ~text_pol~:
   #+begin_src R

   #+end_src

8) Why is the polarity of Beyonce's lyrics 0.25, and why is the
   polarity of Jay Z's lyrics 0?
   #+begin_quote
   Answer:
   #+end_quote

* Exercise: amplification and negation words

- Here you will adjust the negative words to account for the specific
  text. You will then compare the basic and custom ~polarity()~ scores.

- A popular song from Twenty One Pilots is called [[https://youtu.be/pXRviuL6vMY]["Stressed Out"]]
  (2015). If you scan the song lyrics, you will observe the song is
  about youthful nostalgia. Overall, most people would say the
  polarity is negative. Repeatedly the lyrics mention stress, fears
  and pretending.

- Let's compare the song lyrics using the default subjectivity lexicon
  and also a custom one.

- To start, you need to verify the ~key.pol~ subjectivity lexicon does
  not already have the term you want to add. One way to check is with
  ~grep~. The pattern matching ~grep()~ function returns the row
  containing characters that match a search ~pattern~. Here is an
  example where the column ~col~ of ~df~ is searched for "search_pattern":
  #+begin_example R
    idx <- grep(pattern="search_pattern", x=df$col)
  #+end_example

- The vector ~idx~ can now be used to return all elements of ~df~ that
  match the pattern as ~df[idx, ]~.

- After verifying the slang or new word is not already in the ~key.pol~
  lexicon you need to add it.

-----

1) Add [[https://www.google.com/search?q=twenty+one+pilots+stressed+out+lyrics][the lyrics]] as a single string from the file ~stressed_out.txt~
   and store it in the vector ~stressed_out~, then replace ~\\~ by ~\~ with
   ~gsub~ and print the lyrics in ~stressed_out~:
   #+begin_src R
     stressed_out <- readLines("https://bit.ly/stressed_out_txt")
     gsub("\\\\n","\n",stressed_out) -> stressed_out

   #+end_src

2) Compute the default ~polarity~ score of ~stressed_out~:
   #+begin_src R

   #+end_src

3) Bonus question: can you show just the value for the polarity? Tip:
   ~polarity(stressed_out)~ is a ~list~ and "polarity" is a member of the
   ~$all~ element of that list (you can check that with ~str~):
   #+begin_src R

   #+end_src
   
4) Check ~key.pol~ for any words containing "stress":
   1. use ~grep~ to index the data frame by searching in the ~x~ column
   2. save the result in ~rowindex~
   #+begin_src R

   #+end_src

5) Construct a new polarity lexicon ~custom_pol~ using
   ~sentiment_frame~. This function creates a sentiment lookup table for
   use with the ~polarity.frame~ argument of ~polarity~ (i.e. the
   lexicon) - check the function's arguments:
   #+begin_src R

   #+end_src

6) Pass ~positive.words~ as ~positives~ argument to the function
      ~sentiment_frame~, and for the second argument concatenate (with ~c~)
      ~negative_words~ and the words "stressed" and "turn back". Save the
      result in ~custom_pol~
      #+begin_src R :results silent

      #+end_src

7) Compute the ~polarity~ using the ~custom_pol~ lexicon as
      ~polarity.frame~:
      #+begin_src R

      #+end_src

8) You should see that the modified lexicon leads to a more realistic
   sentiment scoring than the standard lexicon.



